{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bccfff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed67f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ec72b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/anqizhao/Anqi/Bert Classifier'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_path = os.getcwd()\n",
    "curr_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12616f95",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24abca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model name\n",
    "model_name = 'bert-base-chinese' \n",
    "# set the checkpoint dirctory\n",
    "checkpoint_dir = 'checkpoints/BERT'\n",
    "label_cols = [ '信息支持1-病情描述/分析/诊断',\n",
    "              '信息支持2-科普读物/其他病人经历',\n",
    "     '信息支持3-线上/门诊或住院流程/时间/费用',\n",
    "     '信息支持4-治疗建议',\n",
    "             '信息支持',\n",
    "             '情感支持'] \n",
    "#label_col = '信息支持1-病情描述/分析/诊断'\n",
    "#label_col = '信息支持2-科普读物/其他病人经历'\n",
    "#label_col = '信息支持3-线上/门诊或住院流程/时间/费用'\n",
    "#label_col = '信息支持4-治疗建议'\n",
    "# label_col = '信息支持'\n",
    "label_col= '情感支持'\n",
    "\n",
    "dataset_folder = 'dataset_622'\n",
    "if not os.path.exists(dataset_folder):\n",
    "    os.makedirs(dataset_folder)\n",
    "    \n",
    "classifier_folder = 'Classifier'\n",
    "if not os.path.exists(classifier_folder):\n",
    "    os.makedirs(classifier_folder)\n",
    "\n",
    "parameter = '_622_5e-5'\n",
    "train_path = os.path.join(curr_path, dataset_folder, label_col[:5]+'_train.csv')\n",
    "val_path = os.path.join(curr_path, dataset_folder, label_col[:5]+'_val.csv')\n",
    "test_path = os.path.join(curr_path,dataset_folder, label_col[:5]+'_test.csv') \n",
    "model_path = os.path.join(curr_path, classifier_folder, label_col[:5]+parameter +'_model')\n",
    "predict_path = os.path.join(curr_path, classifier_folder, label_col[:5]+parameter + '_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc58c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da646173",
   "metadata": {},
   "source": [
    "# Train and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a552db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 17028\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2886\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2886\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/anqizhao/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2130' max='2130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2130/2130 05:56, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.057909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.033651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anqizhao/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "情感支持\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anqizhao/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model\n",
    "dataset = load_dataset('csv', data_files={'train': [train_path], 'val': [val_path],'test':[test_path]})\n",
    "print(dataset)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)\n",
    "# the dataset.map will avoid the RAM crash in the tokenized process if the dataset is too large\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "# 将模型设置为评估模式\n",
    "#model.eval()\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = checkpoint_dir,\n",
    "    num_train_epochs = 2,\n",
    "    logging_steps = 10,\n",
    "    load_best_model_at_end = True,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    per_device_train_batch_size = 4,\n",
    "    per_device_eval_batch_size = 4,\n",
    "    warmup_steps = 100,\n",
    "#     weight_decay = 0.01,\n",
    "    logging_dir = 'logs',\n",
    "    save_total_limit =20,\n",
    "    seed=seed,\n",
    "    learning_rate=5e-5\n",
    "#         learning_rate = 5e-5, 3e-5\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"val\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "#train the model\n",
    "trainer.train()\n",
    "#save the final model\n",
    "trainer.save_model(model_path) \n",
    "\n",
    "print(label_col)\n",
    "pred_dataset = tokenized_dataset[\"test\"]\n",
    "# Run predictions\n",
    "predictions = trainer.predict(pred_dataset)\n",
    "# map labels and their meanings\n",
    "model.config.id2label[0] = '0'\n",
    "model.config.id2label[1] = '1'\n",
    "model.config.id2label\n",
    "# Transform predictions to labels\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "labels = pd.Series(preds).map(model.config.id2label)\n",
    "scores = (np.exp(predictions[0])/np.exp(predictions[0]).sum(-1,keepdims=True)).max(1)\n",
    "df_test = pd.read_csv(test_path)\n",
    "pred_texts = df_test['text'].astype('str').tolist()\n",
    "original_label = df_test['label'].tolist()\n",
    "# Create DataFrame with texts, predictions, labels, and prediction scores\n",
    "df = pd.DataFrame(list(zip(pred_texts,preds,original_label,scores)), columns=['text','pred','original_label','score'])\n",
    "df['pred'].value_counts()\n",
    "df.to_csv(predict_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1008be",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f67b57c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "情感支持\n",
      "acc is: 0.9948024948024948\n",
      "recall is: 0.8181818181818182\n",
      "precision is: 0.8372093023255814\n",
      "f1 is: 0.8275862068965518\n",
      "               Pred Negative  Pred Positive\n",
      "True Negative           2835              7\n",
      "True Positive              8             36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2842\n",
      "           1       0.84      0.82      0.83        44\n",
      "\n",
      "    accuracy                           0.99      2886\n",
      "   macro avg       0.92      0.91      0.91      2886\n",
      "weighted avg       0.99      0.99      0.99      2886\n",
      "\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------')\n",
    "print(label_col)\n",
    "df = pd.read_csv(predict_path)\n",
    "y_ture = df['original_label']\n",
    "y_pred = df['pred']\n",
    "acc = metrics.accuracy_score(y_ture, y_pred)\n",
    "f1 = metrics.f1_score(y_ture, y_pred, labels=[0, 1])\n",
    "recall = metrics.recall_score(y_ture, y_pred, labels=[0, 1])\n",
    "precision = metrics.precision_score(y_ture, y_pred, labels=[0, 1])\n",
    "matrix = metrics.confusion_matrix(y_ture, y_pred, labels=[0, 1])\n",
    "report = metrics.classification_report(y_ture, y_pred, labels=[0, 1])\n",
    "\n",
    "print('acc is: '+ str(acc))\n",
    "print('recall is: '+ str(recall))\n",
    "print('precision is: '+ str(precision))\n",
    "print('f1 is: '+ str(f1))\n",
    "class_names1 = ['True Negative', 'True Positive']\n",
    "class_names2 = ['Pred Negative', 'Pred Positive']\n",
    "df_cm = pd.DataFrame(matrix, index=class_names1, columns=class_names2)\n",
    "print(df_cm)\n",
    "print(report)\n",
    "print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ace29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
